{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaiveBayes implementation to classify song genre \n",
    "### Tasneem Abed (1408535)\n",
    "#### COMS4030A project 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes implementation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"FinalNorm.csv\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.copy()\n",
    "for i in range(0, df.shape[0]):\n",
    "    df.lyrics.loc[i] = df.lyrics.loc[i].replace('~', ' ')\n",
    "    df.lyrics.loc[i] = df.lyrics.loc[i].replace(\"'\", '')\n",
    "df = df.drop(['WPL', 'Unique WPL', 'Token ration', 'Mean word length', 'Total'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "country = 0<br> pop = 1<br> rap = 2<br> rock = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode genre:\n",
    "for i in range(0, df.shape[0]):\n",
    "    if (i>= 0 and i<750):\n",
    "        df.genre.iloc[i] = 0\n",
    "    elif (i>= 750 and i<1500):\n",
    "        df.genre.iloc[i] = 1\n",
    "    elif (i>= 1500 and i<2250):\n",
    "        df.genre.iloc[i] = 2\n",
    "    elif (i>= 2250 and i<3000):\n",
    "        df.genre.iloc[i] = 3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster=LancasterStemmer()\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Stemming\n",
    "for i in range(0, df.shape[0]):\n",
    "    df.lyrics.iloc[i] = stemSentence(df.lyrics.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftover, newtraining = train_test_split(df, test_size=0.7)\n",
    "newtraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtraining.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = [], []\n",
    "\n",
    "for row in df.iterrows():\n",
    "    index, data = row\n",
    "    k = data[2]\n",
    "    r = k.split() #Splits the string into individual words by space\n",
    "    t = list(set(r)) #All the unique words ['aint', 'make', 'the'...]\n",
    "    g = ' '.join(t) #Takes the list and makes it a single string\n",
    "    x.append(g)\n",
    "    y.append(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the balance of the classes\n",
    "print(y_test.count(0))\n",
    "print(y_test.count(1))\n",
    "print(y_test.count(2))\n",
    "print(y_test.count(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get individual lists for each genre\n",
    "xCo = [x_train[i] for i in range(len(x_train)) if y_train[i] == 0]\n",
    "xPop = [x_train[i] for i in range(len(x_train)) if y_train[i] == 1]\n",
    "xRap = [x_train[i] for i in range(len(x_train)) if y_train[i] == 2]\n",
    "xRock = [x_train[i] for i in range(len(x_train)) if y_train[i] == 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "country_words = []\n",
    "pop_words = []\n",
    "rap_words = []\n",
    "rock_words = []\n",
    "\n",
    "for i in range(0, len(x_train)):\n",
    "    h = x_train[i].split()\n",
    "    for j in range(0, len(h)):\n",
    "#         if len(h[j]) > 2:   #Remove stop words\n",
    "        words.append(h[j])\n",
    "\n",
    "for k in range(0, len(xCo)):\n",
    "    fo = xCo[k].split()\n",
    "    for l in range(0, len(fo)):\n",
    "#         if len(fo[l]) > 2:   #Remove stop words\n",
    "         country_words.append(fo[l]) \n",
    "\n",
    "for m in range(0, len(xPop)):\n",
    "    fa = xPop[m].split()\n",
    "    for n in range(0, len(fa)):\n",
    "#         if len(fa[n]) > 2:   #Remove stop words\n",
    "        pop_words.append(fa[n]) \n",
    "        \n",
    "for o in range(0, len(xRap)):\n",
    "    fi = xRap[o].split()\n",
    "    for p in range(0, len(fi)):\n",
    "#         if len(fi[p]) > 2:   #Remove stop words\n",
    "        rap_words.append(fi[p]) \n",
    "        \n",
    "for q in range(len(xRock)):\n",
    "    fu = xRock[q].split()\n",
    "    for t in range(len(fu)):\n",
    "#         if len(fu[t]) > 2:   #Remove stop words\n",
    "        rock_words.append(fu[t]) \n",
    "                \n",
    "print(len(country_words), len(pop_words), len(rap_words), len(rock_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prior probabilities\n",
    "priorC = len(xCo)/len(x_train)\n",
    "priorP = len(xPop)/len(x_train)\n",
    "priorRap = len(xRap)/len(x_train)\n",
    "priorRock = len(xRock)/len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict = {}\n",
    "pop_dict = {}\n",
    "rap_dict = {}\n",
    "rock_dict = {}\n",
    "\n",
    "for i in range(0, len(words)):\n",
    "    country_dict[words[i]] = (country_words.count(words[i])+1)\n",
    "    pop_dict[words[i]] = (pop_words.count(words[i])+1)\n",
    "    rap_dict[words[i]] = (rap_words.count(words[i])+1)\n",
    "    rock_dict[words[i]] = (rock_words.count(words[i])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "import math\n",
    "predictions = []\n",
    "\n",
    "for i in range(0, len(x_test)):\n",
    "    print(i)\n",
    "    testlyric = x_test[i]\n",
    "    lyric_words = testlyric.split() #Array of separate words from single review    \n",
    "    c = 0\n",
    "    po = 0\n",
    "    ra = 0\n",
    "    ro = 0\n",
    "    for key in country_dict.keys():  #P(test lyric | pop)\n",
    "        if key in lyric_words:\n",
    "            ct = (country_dict[key] / (len(xCo)+4))\n",
    "        else:\n",
    "            ct = 1- (country_dict[key] / (len(xCo)+4))\n",
    "        c = c+ abs(math.log10(ct))\n",
    "        \n",
    "    for key in pop_dict.keys():\n",
    "        if key in lyric_words:\n",
    "            pt = (pop_dict[key] / (len(xPop)+4))\n",
    "        else:\n",
    "            pt = 1-(pop_dict[key] / (len(xPop)+4))\n",
    "        po = po+ abs(math.log10(pt))\n",
    "\n",
    "    for key in rap_dict.keys():\n",
    "        if key in lyric_words:\n",
    "            rt = (rap_dict[key] / (len(xRap)+4))\n",
    "        else:\n",
    "            rt = 1-(rap_dict[key] / (len(xRap)+4))\n",
    "        ra = ra + abs(math.log10(rt))\n",
    "            \n",
    "    for key in rock_dict.keys():\n",
    "        if key in lyric_words:\n",
    "            rot = (rock_dict[key]/ (len(xRock)+4))\n",
    "        else:\n",
    "            rot = 1-(rock_dict[key]/ (len(xRock)+4))\n",
    "        ro = ro + abs(math.log10(rot)) \n",
    "\n",
    "    normalization = ((c*priorC)+(po*priorP)+(ra*priorRap)+(ro*priorRock)) \n",
    "    NB = []\n",
    "    NB.append((c*priorC) / normalization) #P(country | lyric)\n",
    "    NB.append((po*priorP)/ normalization)\n",
    "    NB.append((ra*priorRap)/ normalization)\n",
    "    NB.append((ro*priorRock)/ normalization)\n",
    "    pred = NB.index(min(NB))\n",
    "#     print(testery[i], pred)\n",
    "    predictions.append(pred)\n",
    "#     print(NB)\n",
    "    \n",
    "# classification_error_train = np.sum(y_train != predictions) / len(x_train)\n",
    "classification_error_test = np.sum(y_test != predictions) / len(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing error: \", classification_error_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = np.zeros((4,4))\n",
    "correct = 0\n",
    "for i in range(0,len(y_test)):\n",
    "    label = y_test[i]\n",
    "    prediction = predictions[i]\n",
    "    if (prediction == label):\n",
    "        correct += 1\n",
    "    confusion[prediction, label] += 1\n",
    "accuracy = (correct/(len(x_test))) * 100\n",
    "print(\"Accuracy: %.4f\" %(accuracy))\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
